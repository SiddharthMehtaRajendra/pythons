{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fer map\n",
    "emotion_dict = {0: \"Anger\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happiness\", 4: \"Sadness\", 5: \"Surprise\", 6: \"Neutral\"}\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config = Config(\n",
    "    num_classes = 7,\n",
    "    width = 224,\n",
    "    height = 224,\n",
    "    num_epochs = 30,\n",
    "    batch_size = 32,\n",
    "    feat_dim = 7,\n",
    "    lr_cent = 0.5,\n",
    "    closs_weight = 0.5,\n",
    "    ckp = True,\n",
    "    fer = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type BaselineModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type ConvBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:462: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if original_source != current_source:\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type LinearBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/sumeet/anaconda2/lib/python2.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineModel(\n",
       "  (net): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Flatten()\n",
       "    (4): LinearBlock(\n",
       "      (linblock): Sequential(\n",
       "        (0): Linear(in_features=2304, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (5): LinearBlock(\n",
       "      (linblock): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (6): LinearBlock(\n",
       "      (linblock): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (7): Linear(in_features=128, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=kernel_size, stride=stride, padding=(1,1)),\n",
    "                          nn.BatchNorm2d(C_out),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(in_channels=C_out, out_channels=C_out, kernel_size=kernel_size, stride=stride, padding=(1,1)),\n",
    "                          nn.BatchNorm2d(C_out),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.linblock = nn.Sequential(\n",
    "                          nn.Linear(insize, outsize),\n",
    "                          nn.BatchNorm1d(outsize),\n",
    "                          nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linblock(x)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        layers = []\n",
    "        num_classes = 7\n",
    "        channels = [1, 256, 128, 64] # this needs to be modified according to num_blocks\n",
    "        linear_size = [64*6*6, 512, 256, 128]\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            layers.append(ConvBlock(C_in=channels[i], C_out=channels[i+1], kernel_size=3, stride=1))\n",
    "        \n",
    "        layers.append(Flatten())\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            layers.append(LinearBlock(linear_size[i], linear_size[i+1]))\n",
    "        \n",
    "        layers.append(nn.Linear(linear_size[i+1], config.num_classes))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "    \n",
    "model = BaselineModel(num_blocks=3)\n",
    "model = torch.load('models/fer_adam_cent_20.pth', map_location=torch.device('cpu'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('frame shape: ', (490, 640, 3))\n",
      "tensor([[-0.0992, -2.0119, -0.0718,  0.4170,  1.8168, -0.7470, -0.1515]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Read the input image\n",
    "frame = cv2.imread('imgs/test6.png')\n",
    "\n",
    "\n",
    "# Convert into grayscale\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "print(\"frame shape: \", frame.shape)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "\n",
    "# Draw the rectangle around each face\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    \n",
    "    \n",
    "    cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (224, 224)), 0), 0)\n",
    "    cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "    \n",
    "#     print(\"img shape: \", cropped_img.shape)\n",
    "#     print(type(cropped_img))\n",
    "    \n",
    "#     cropped_img = torch.from_numpy(cropped_img)\n",
    "#     cropped_img = cropped_img.float()\n",
    "\n",
    "    img = Image.fromarray(frame)\n",
    "    img_pil = torchvision.transforms.Resize((48,48))(img)\n",
    "    img = torchvision.transforms.ToTensor()(img_pil)\n",
    "    img = img/255\n",
    "    \n",
    "    if img.shape[0] == 3:\n",
    "        img = torchvision.transforms.Grayscale(num_output_channels=1)(img_pil)\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        \n",
    "        \n",
    "    img = img.unsqueeze(dim=0)\n",
    "    prediction = model(img)\n",
    "        \n",
    "    print(prediction)\n",
    "    print(torch.argmax(prediction).item())\n",
    "    cv2.putText(frame, emotion_dict[int(torch.argmax(prediction).item())], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    \n",
    "# Display\n",
    "cv2.imshow('frame', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # To capture video from webcam. \n",
    "# cap = cv2.VideoCapture(0)\n",
    "# # # To use a video file as input \n",
    "# # cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "# # # Load the cascade\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     # Read the frame\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Convert to grayscale\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Detect the faces\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "#     # Draw the rectangle around each face\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "#         roi_gray = gray[y:y + h, x:x + w]\n",
    "# #         cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "#         cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (224, 224)), 0), 0)\n",
    "\n",
    "#         cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "\n",
    "#         cropped_img = torch.from_numpy(cropped_img)\n",
    "#         cropped_img = cropped_img.float()\n",
    "#         prediction = model(cropped_img)\n",
    "        \n",
    "#         print(prediction)\n",
    "#         cv2.putText(frame, emotion_dict[int(torch.argmax(prediction).item())], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "#     # Display\n",
    "#     cv2.imshow('frame', frame)\n",
    "    \n",
    "#     # Stop if q key is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "        \n",
    "# # Release the VideoCapture object\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
