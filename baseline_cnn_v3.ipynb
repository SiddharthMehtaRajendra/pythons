{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hdRpCepJz7XV",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "34BLnzCbzd6w",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "#327\n",
    "train_size= 195\n",
    "val_size= 66\n",
    "test_size = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CXc2tVVQ7Cds",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_data(datadir, label_map):\n",
    "    img_list = []\n",
    "    file_list = []\n",
    "    \n",
    "    for root, directories, filenames in os.walk(datadir):      \n",
    "        for filename in filenames:\n",
    "            file_list.append(filename)\n",
    "            if filename.endswith('.png'):\n",
    "                \n",
    "                filei = os.path.join(root, filename)\n",
    "                file_ids = filename.split('_')\n",
    "                file_id = file_ids[0] + '_' + file_ids[1]\n",
    "                if file_id in label_map:\n",
    "                    img_list.append(filei)\n",
    "    \n",
    "    return img_list[:train_size], img_list[train_size:train_size+val_size], img_list[train_size+val_size: train_size+val_size+test_size]\n",
    "\n",
    "\n",
    "\n",
    "def parse_emotion_data(datadir):\n",
    "    em_map = {}\n",
    "    file_list = []\n",
    "    for root, directories, filenames in os.walk(datadir):\n",
    "        for filename in filenames:\n",
    "            file_list.append(filename)\n",
    "            if filename.endswith('.txt'):\n",
    "                   \n",
    "                f = open(root +  \"/\" + filename, 'r')\n",
    "                lines = []\n",
    "                for line in f.readlines():\n",
    "                    lines.append(line)\n",
    "                value = lines[0]\n",
    "                f.close()\n",
    "                \n",
    "                keys = filename.split('_')\n",
    "                key = keys[0] + '_' + keys[1]\n",
    "                em_map[key] = int(float(value.strip())) - 1\n",
    "                \n",
    "    return em_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c56ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_map = parse_emotion_data(\"Emotion\")\n",
    "train_img_list, val_img_list, test_img_list = parse_data(\"cohn-kanade-images\", label_map)\n",
    "\n",
    "freq_count = collections.Counter(label_map.values())\n",
    "counts = [freq_count[key] for key in sorted(freq_count.keys())]\n",
    "\n",
    "bins = 30\n",
    "plt.hist(label_map.values(), bins, facecolor='blue', alpha=0.7)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1572058491942,
     "user": {
      "displayName": "Mohit Grover",
      "photoUrl": "",
      "userId": "17020987855024013058"
     },
     "user_tz": 420
    },
    "id": "tTjycRTo9_KN",
    "outputId": "95d0dd64-73dd-47cc-8d4e-993b43bd77d0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, label_map):\n",
    "        self.file_list = file_list\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.file_list[index])\n",
    "        img_pil = torchvision.transforms.Resize((224,224))(img)\n",
    "        img = torchvision.transforms.ToTensor()(img_pil)\n",
    "        if img.shape[0] == 3:\n",
    "            img = torchvision.transforms.Grayscale(num_output_channels=1)(img_pil)\n",
    "            img = torchvision.transforms.ToTensor()(img)\n",
    "        keys = self.file_list[index].split('/')[-1].split('.')[0].split('_')\n",
    "        label = self.label_map[keys[0] + '_' + keys[1]]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8WkNa73xzd63",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_img_list, label_map)\n",
    "dev_dataset = ImageDataset(val_img_list, label_map)\n",
    "test_dataset = ImageDataset(test_img_list, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# len(train_dataset)\n",
    "# print(train_img_list)\n",
    "# for i in range(190):\n",
    "#     print(train_dataset[i][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DQWaXqRtzd65",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset, dev_dataset, test_dataset = torch.utils.data.random_split(dataset, (train_size, val_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "w2FJRhYXzd66",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(train_dataset)):\n",
    "#     print(train_dataset[i][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cCO6k3Yfzd69",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, \n",
    "                                               shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Wj46-XYLzd6_",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=64, \n",
    "                                               shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1Wxrwfckzd7B",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "                          nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=kernel_size, stride=stride),\n",
    "                          nn.ReLU(),\n",
    "                          nn.MaxPool2d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        layers = []\n",
    "        num_classes = 7\n",
    "        channels = [1, 64, 128, 256] # this needs to be modified according to num_blocks\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            layers.append(ConvBlock(C_in=channels[i], C_out=channels[i+1], kernel_size=5, stride=1))\n",
    "        \n",
    "        layers.append(nn.Dropout(p=0.25))\n",
    "        \n",
    "        layers.append(Flatten())\n",
    "        \n",
    "        layers.append(nn.Linear(256*24*24, 512))\n",
    "        \n",
    "        layers.append(nn.Dropout(p=0.5))\n",
    "        \n",
    "        layers.append(nn.Linear(512, num_classes))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6150,
     "status": "ok",
     "timestamp": 1572056426800,
     "user": {
      "displayName": "Tejasri Thota",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA-qo0IWRkoBECjG3L_eRQ7NjBOkZxcaesklum9=s64",
      "userId": "10780644812533486358"
     },
     "user_tz": 420
    },
    "id": "re2Kdhiazd7C",
    "outputId": "bfb5ad37-62c5-4bf4-e910-452f67ca8b17",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineModel(\n",
      "  (net): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "    (4): Flatten()\n",
      "    (5): Linear(in_features=147456, out_features=512, bias=True)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel(num_blocks=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kRLEOoHdzd7E",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model,n_epochs,train_dataloader, test_loader):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    eval_accs = []\n",
    "    for epoch in range(n_epochs):\n",
    "        avg_loss = 0.0\n",
    "        for batch_num, (feats, labels) in enumerate(train_dataloader):\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feats)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            if batch_num % 50 == 49:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n",
    "                logging.debug('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n",
    "                avg_loss = 0.0    \n",
    "        \n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "            del loss\n",
    "        train_losses.append(avg_loss)\n",
    "        test_loss, test_accuracy = test_classify_loss(model,test_loader)\n",
    "        eval_losses.append(test_loss)\n",
    "        eval_accs.append(test_accuracy)\n",
    "        print('Epoch: {}\\tTrain Loss: {}\\tTest-Loss: {}\\tTest-acc: {:.4f}'.format(epoch+1, avg_loss, test_loss, test_accuracy))\n",
    "    return train_losses, eval_losses, eval_accs\n",
    "\n",
    "def test_classify_loss(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        accuracies = []\n",
    "        total = 0\n",
    "        for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            outputs = model(feats)\n",
    "            _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "         \n",
    "            loss = criterion(outputs, labels.long())\n",
    "            accuracies += [float(torch.sum(torch.eq(pred_labels, labels)).item())/float(len(labels))]\n",
    "            test_loss.extend([loss.item()]*feats.size()[0])\n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "    model.train()\n",
    "    return np.mean(test_loss), np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30341,
     "status": "error",
     "timestamp": 1572056451006,
     "user": {
      "displayName": "Tejasri Thota",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA-qo0IWRkoBECjG3L_eRQ7NjBOkZxcaesklum9=s64",
      "userId": "10780644812533486358"
     },
     "user_tz": 420
    },
    "id": "ACkvD4NVzd7G",
    "outputId": "9e3fc8f9-69ae-45f6-de28-8bdbbeb73637",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_losses, eval_losses, eval_accs = train(model,200, train_dataloader,dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "d6AXVsznzd7J",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_losses)\n",
    "plt.savefig(\"training_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(eval_accs)\n",
    "plt.savefig(\"val_acc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "baseline_cnn (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
